{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0566d97-5fd9-46df-a2c9-3886844bb89b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 7, 2])\n",
      "Initial x tensor:\n",
      "tensor([[[ 1.,  0.],\n",
      "         [ 3., -1.],\n",
      "         [12., 10.],\n",
      "         [ 1., 10.],\n",
      "         [11., 10.],\n",
      "         [10., 10.],\n",
      "         [ 0.,  1.]],\n",
      "\n",
      "        [[ 1.,  0.],\n",
      "         [ 3., -1.],\n",
      "         [12., 10.],\n",
      "         [ 1., 10.],\n",
      "         [11., 10.],\n",
      "         [10., 10.],\n",
      "         [ 0.,  1.]]])\n",
      "src tensor:\n",
      "tensor([[[ 1.,  0.],\n",
      "         [12., 10.],\n",
      "         [11., 10.],\n",
      "         [ 0.,  1.]],\n",
      "\n",
      "        [[ 1.,  0.],\n",
      "         [12., 10.],\n",
      "         [11., 10.],\n",
      "         [ 0.,  1.]]])\n",
      "dst tensor:\n",
      "tensor([[[ 3., -1.],\n",
      "         [ 1., 10.],\n",
      "         [10., 10.]],\n",
      "\n",
      "        [[ 3., -1.],\n",
      "         [ 1., 10.],\n",
      "         [10., 10.]]])\n",
      "unm_idx tensor:\n",
      "tensor([[[3],\n",
      "         [0]],\n",
      "\n",
      "        [[3],\n",
      "         [0]]])\n",
      "unm tensor:\n",
      "tensor([[[0., 1.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [1., 0.]]])\n",
      "src_idx tensor:\n",
      "tensor([[[2],\n",
      "         [1]],\n",
      "\n",
      "        [[2],\n",
      "         [1]]])\n",
      "src (after gather) tensor:\n",
      "tensor([[[11., 10.],\n",
      "         [12., 10.]],\n",
      "\n",
      "        [[11., 10.],\n",
      "         [12., 10.]]])\n",
      "dst_idx tensor:\n",
      "tensor([[[2],\n",
      "         [2]],\n",
      "\n",
      "        [[2],\n",
      "         [2]]])\n",
      "dst (after scatter_reduce) tensor:\n",
      "tensor([[[ 3., -1.],\n",
      "         [ 1., 10.],\n",
      "         [11., 10.]],\n",
      "\n",
      "        [[ 3., -1.],\n",
      "         [ 1., 10.],\n",
      "         [11., 10.]]])\n",
      "Final result tensor:\n",
      "tensor([[[ 0.,  1.],\n",
      "         [ 1.,  0.],\n",
      "         [ 3., -1.],\n",
      "         [ 1., 10.],\n",
      "         [11., 10.]],\n",
      "\n",
      "        [[ 0.,  1.],\n",
      "         [ 1.,  0.],\n",
      "         [ 3., -1.],\n",
      "         [ 1., 10.],\n",
      "         [11., 10.]]])\n",
      "x new tensor([[[ 0.,  1.],\n",
      "         [ 1.,  0.],\n",
      "         [ 3., -1.],\n",
      "         [ 1., 10.],\n",
      "         [11., 10.]],\n",
      "\n",
      "        [[ 0.,  1.],\n",
      "         [ 1.,  0.],\n",
      "         [ 3., -1.],\n",
      "         [ 1., 10.],\n",
      "         [11., 10.]]])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "\n",
    "from mamba_ssm.modules.mamba_simple import Mamba\n",
    "import sys\n",
    "from vim import models_mamba\n",
    "\n",
    "import math\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from tome.merge import bipartite_soft_matching, merge_source, merge_wavg\n",
    "def compare_tensors(self,t1,t2):\n",
    "        t1_slice = t1[0, :30, :]\n",
    "        t2_slice = t2[0, :30, :]\n",
    "        \n",
    "        # Calculating the Euclidean distance for each of the first 30 tokens\n",
    "        distances = torch.norm(t1_slice - t2_slice, dim=-1)\n",
    "        \n",
    "        # Convert distances to a list (optional)\n",
    "        distances_list = distances.tolist()\n",
    "        \n",
    "        # Output the distances\n",
    "        print(distances_list)\n",
    "x = torch.tensor([[[1.0, 0.0], \n",
    "                   [3,-1],# Token 1\n",
    "                   [12.0, 10.0],   # Token 2\n",
    "                   [1, 10],   # Token 3\n",
    "                   [11.0, 10.0],   # Token 4\n",
    "                   [10, 10],\n",
    "                   [0, 1]], \n",
    "                  [[1.0, 0.0], \n",
    "                   [3,-1],# Token 1\n",
    "                   [12.0, 10.0],   # Token 2\n",
    "                   [1, 10],   # Token 3\n",
    "                   [11.0, 10.0],   # Token 4\n",
    "                   [10, 10],\n",
    "                   [0, 1]]\n",
    "                 ])\n",
    "print(x.shape)\n",
    "merge, _,_ =  bipartite_soft_matching(\n",
    "                x,\n",
    "                2,\n",
    "                False,\n",
    "                False,\n",
    "            )\n",
    "x_new = merge(x)\n",
    "# distances = torch.norm(x[:,:-1,:]-x_new,dim=-1)\n",
    "# print(distances)\n",
    "print(f\"x new {x_new}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74cd9383-dfd1-463d-87a6-9cb301344ebb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1950194434.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    scores tensor([[[0.0000, 0.6402],\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "scores tensor([[[0.0000, 0.6402],\n",
    "         [0.7071, 0.9959],\n",
    "         [0.8137, 0.9972]],\n",
    "\n",
    "        [[0.0000, 0.6402],\n",
    "         [0.7071, 0.9959],\n",
    "         [0.8137, 0.9972]]])\n",
    "node_maxtensor([[  -inf, 0.9959, 0.9972],\n",
    "        [  -inf, 0.9959, 0.9972]])\n",
    "node_idxtensor([[0, 1, 1],\n",
    "        [0, 1, 1]])\n",
    "edge_idx`n tensor([[[2],\n",
    "         [1],\n",
    "         [0]],\n",
    "\n",
    "        [[2],\n",
    "         [1],\n",
    "         [0]]])\n",
    "unm_idx`n tensor([[[1],\n",
    "         [0]],\n",
    "\n",
    "        [[1],\n",
    "         [0]]])\n",
    "src_idx`n tensor([[[2]],\n",
    "\n",
    "        [[2]]])\n",
    "dst_idx`n tensor([[[1]],\n",
    "\n",
    "        [[1]]])\n",
    "Initial x tensor:\n",
    "tensor([[[ 1.0000,  0.0000],\n",
    "         [ 0.0000, 10.0000],\n",
    "         [ 0.4000,  0.4000],\n",
    "         [ 0.5000,  0.6000],\n",
    "         [ 0.5000,  0.7000]],\n",
    "\n",
    "        [[ 1.0000,  0.0000],\n",
    "         [ 0.0000, 10.0000],\n",
    "         [ 0.4000,  0.4000],\n",
    "         [ 0.5000,  0.6000],\n",
    "         [ 0.5000,  0.7000]]])\n",
    "src tensor:\n",
    "tensor([[[1.0000, 0.0000],\n",
    "         [0.4000, 0.4000],\n",
    "         [0.5000, 0.7000]],\n",
    "\n",
    "        [[1.0000, 0.0000],\n",
    "         [0.4000, 0.4000],\n",
    "         [0.5000, 0.7000]]])\n",
    "dst tensor:\n",
    "tensor([[[ 0.0000, 10.0000],\n",
    "         [ 0.5000,  0.6000]],\n",
    "\n",
    "        [[ 0.0000, 10.0000],\n",
    "         [ 0.5000,  0.6000]]])\n",
    "unm_idx tensor:\n",
    "tensor([[[0],\n",
    "         [1]],\n",
    "\n",
    "        [[0],\n",
    "         [1]]])\n",
    "unm tensor:\n",
    "tensor([[[1.0000, 0.0000],\n",
    "         [0.4000, 0.4000]],\n",
    "\n",
    "        [[1.0000, 0.0000],\n",
    "         [0.4000, 0.4000]]])\n",
    "src_idx tensor:\n",
    "tensor([[[2]],\n",
    "\n",
    "        [[2]]])\n",
    "src (after gather) tensor:\n",
    "tensor([[[0.5000, 0.7000]],\n",
    "\n",
    "        [[0.5000, 0.7000]]])\n",
    "dst_idx tensor:\n",
    "tensor([[[1]],\n",
    "\n",
    "        [[1]]])\n",
    "dst (after scatter_reduce) tensor:\n",
    "tensor([[[ 0.0000, 10.0000],\n",
    "         [ 0.5000,  0.6500]],\n",
    "\n",
    "        [[ 0.0000, 10.0000],\n",
    "         [ 0.5000,  0.6500]]])\n",
    "Final result tensor:\n",
    "tensor([[[ 1.0000,  0.0000],\n",
    "         [ 0.0000, 10.0000],\n",
    "         [ 0.4000,  0.4000],\n",
    "         [ 0.5000,  0.6500]],\n",
    "\n",
    "        [[ 1.0000,  0.0000],\n",
    "         [ 0.0000, 10.0000],\n",
    "         [ 0.4000,  0.4000],\n",
    "         [ 0.5000,  0.6500]]])\n",
    "tensor([[0.0000, 0.0000, 0.0000, 0.0500],\n",
    "        [0.0000, 0.0000, 0.0000, 0.0500]])\n",
    "x new tensor([[[ 1.0000,  0.0000],\n",
    "         [ 0.0000, 10.0000],\n",
    "         [ 0.4000,  0.4000],\n",
    "         [ 0.5000,  0.6500]],\n",
    "\n",
    "        [[ 1.0000,  0.0000],\n",
    "         [ 0.0000, 10.0000],\n",
    "         [ 0.4000,  0.4000],\n",
    "         [ 0.5000,  0.6500]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f820465-629b-4b09-9bc5-02eb577e504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Example tensor\n",
    "input = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "\n",
    "# Indices to gather\n",
    "index = torch.tensor([[0, 1], [2, 0], [1, 0]])\n",
    "\n",
    "# Gather elements from input according to index\n",
    "output = torch.gather(input, 0, index)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aad552fa-1012-4c15-bfcf-eae617ea34ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 18, 20])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Step 1: Create the original tensor\n",
    "tensor = torch.randn(20, 20, 20)\n",
    "\n",
    "# Step 2: Define the index tensor\n",
    "idx_tensor = torch.tensor([10, 15])\n",
    "\n",
    "# Step 3: Remove the specified indices\n",
    "mask = torch.ones(tensor.size(1), dtype=torch.bool)\n",
    "mask[idx_tensor] = False\n",
    "reduced_tensor = tensor[:, mask, :]\n",
    "\n",
    "# Step 4: Check the shape of the resulting tensor\n",
    "print(reduced_tensor.shape)  # Expected output: torch.Size([20, 18, 20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81a8a9da-d959-40b2-aa87-b72218287ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 2])\n",
      "torch.Size([20])\n",
      "torch.Size([20, 18, 20])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Step 1: Create the original tensor\n",
    "tensor = torch.randn(20, 20, 20)\n",
    "\n",
    "# Step 2: Define the index tensor\n",
    "idx_tensors = torch.tensor([[10, 15]] * 20)  # Shape [20, 2]\n",
    "print(idx_tensors.shape)\n",
    "# Step 3: Create a mask for each slice\n",
    "mask = torch.ones(tensor.size(1), dtype=torch.bool)  # Create a mask for the second dimension\n",
    "mask[idx_tensors] = False  # Set the positions to be removed as False\n",
    "print(mask.shape)\n",
    "# Step 4: Apply the mask to the tensor\n",
    "# Use broadcasting and advanced indexing to apply the mask across all slices\n",
    "reduced_tensor = tensor[:, mask, :]\n",
    "\n",
    "# Step 5: Check the shape of the resulting tensor\n",
    "print(reduced_tensor.shape)  # Expected output: torch.Size([20, 18, 20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b4d9a9c-47a3-42d7-915d-feb1f125363f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 2])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 3])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [2, 3] at index 0 does not match the shape of the indexed tensor [2, 3, 2] at index 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest passed successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Run the test\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[43mtest_reduce_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 24\u001b[0m, in \u001b[0;36mtest_reduce_tensor\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(mask\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# reduced_tensor = tensor[torch.arange(2).unsqueeze(1), mask].view(2, 1, 2)\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m reduced_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Check if the output matches the expected tensor\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(reduced_tensor\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [2, 3] at index 0 does not match the shape of the indexed tensor [2, 3, 2] at index 1"
     ]
    }
   ],
   "source": [
    "def test_reduce_tensor():\n",
    "    # Manually created tensor of shape [2, 3, 2]\n",
    "    tensor = torch.tensor([\n",
    "        [[1, 2], [3, 4], [5, 6]],  # First slice\n",
    "        [[7, 8], [9, 10], [11, 12]]  # Second slice\n",
    "    ])\n",
    "    print(tensor.shape)\n",
    "    # Indices to remove from the second dimension for each slice\n",
    "    idx_tensors = torch.tensor([[0, 2], [1, 2]])  # Different indices for each slice\n",
    "    print(idx_tensors.shape)\n",
    "    \n",
    "    # Expected tensor after removing specified indices\n",
    "    expected_tensor = torch.tensor([\n",
    "        [[3, 4]],  # After removing indices 0 and 2 from the first slice\n",
    "        [[7, 8]]   # After removing indices 1 and 2 from the second slice\n",
    "    ])\n",
    "    \n",
    "    # Mask creation and application\n",
    "    mask = torch.ones(tensor.size(0), tensor.size(1), dtype=torch.bool)\n",
    "    mask[torch.arange(2).unsqueeze(1), idx_tensors] = False\n",
    "\n",
    "    print(mask.shape)\n",
    "    # reduced_tensor = tensor[torch.arange(2).unsqueeze(1), mask].view(2, 1, 2)\n",
    "    reduced_tensor = tensor[torch.arange(2)[:, None], mask]\n",
    "    # Check if the output matches the expected tensor\n",
    "    print(reduced_tensor.shape)\n",
    "    assert torch.equal(reduced_tensor, expected_tensor), f\"Test failed: {reduced_tensor} != {expected_tensor}\"\n",
    "    \n",
    "    print(\"Test passed successfully!\")\n",
    "\n",
    "# Run the test\n",
    "test_reduce_tensor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d48b0a34-5917-440d-b3c6-5827805c4e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 2])\n",
      "torch.Size([20, 20])\n",
      "torch.Size([20, 360])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Step 1: Create the original tensor with shape [20, 20, 20]\n",
    "tensor = torch.randn(20, 20, 20)\n",
    "\n",
    "# Step 2: Define idx_tensors, which contains indices to be removed for each batch\n",
    "# For example, we're removing the 10th and 15th indices from each 20x20 slice\n",
    "idx_tensors = torch.tensor([[10, 15]] * 20)  # Repeat the same indices for each slice\n",
    "print(idx_tensors.shape)\n",
    "# Step 3: Create a boolean mask initialized to True for all positions\n",
    "mask = torch.ones(tensor.size(0), tensor.size(1), dtype=torch.bool)\n",
    "\n",
    "# Use advanced indexing to set False in the mask where idx_tensors indicates\n",
    "# mask[i, idx_tensors[i, :]] is set to False for the corresponding batch\n",
    "mask[torch.arange(20).unsqueeze(1), idx_tensors] = False\n",
    "print(mask.shape)\n",
    "# Step 4: Apply the mask to the original tensor\n",
    "# tensor[torch.arange(20)[:, None], mask] filters out the unwanted indices in the second dimension\n",
    "reduced_tensor = tensor[torch.arange(20)[:, None], mask]\n",
    "\n",
    "# Step 5: Verify the shape of the resulting tensor\n",
    "print(reduced_tensor.shape)  # Expected output: torch.Size([20, 18, 20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa16a43f-071e-4ff3-bd8a-81da5f6a0bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor shape: torch.Size([2, 3, 2])\n",
      "idx_tensors shape: torch.Size([2, 2])\n",
      "Mask shape: torch.Size([2, 3])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [2, 3] at index 0 does not match the shape of the indexed tensor [2, 3, 2] at index 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest passed successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Run the test\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[43mtest_reduce_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 27\u001b[0m, in \u001b[0;36mtest_reduce_tensor\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMask shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, mask\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Apply the mask correctly\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m reduced_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Check if the output matches the expected tensor\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReduced tensor shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, reduced_tensor\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [2, 3] at index 0 does not match the shape of the indexed tensor [2, 3, 2] at index 1"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def test_reduce_tensor():\n",
    "    # Manually created tensor of shape [2, 3, 2]\n",
    "    tensor = torch.tensor([\n",
    "        [[1, 2], [3, 4], [5, 6]],  # First slice\n",
    "        [[7, 8], [9, 10], [11, 12]]  # Second slice\n",
    "    ])\n",
    "    print(\"Tensor shape:\", tensor.shape)\n",
    "\n",
    "    # Indices to remove from the second dimension for each slice\n",
    "    idx_tensors = torch.tensor([[0, 2], [1, 2]])  # Different indices for each slice\n",
    "    print(\"idx_tensors shape:\", idx_tensors.shape)\n",
    "    \n",
    "    # Expected tensor after removing specified indices\n",
    "    expected_tensor = torch.tensor([\n",
    "        [[3, 4]],  # After removing indices 0 and 2 from the first slice\n",
    "        [[7, 8]]   # After removing indices 1 and 2 from the second slice\n",
    "    ])\n",
    "    \n",
    "    # Mask creation and application\n",
    "    mask = torch.ones(tensor.size(0), tensor.size(1), dtype=torch.bool)\n",
    "    mask[torch.arange(2).unsqueeze(1), idx_tensors] = False\n",
    "    print(\"Mask shape:\", mask.shape)\n",
    "\n",
    "    # Apply the mask correctly\n",
    "    reduced_tensor = tensor[torch.arange(2)[:, None], mask].view(2, 1, 2)\n",
    "\n",
    "    # Check if the output matches the expected tensor\n",
    "    print(\"Reduced tensor shape:\", reduced_tensor.shape)\n",
    "    print(\"Reduced tensor:\", reduced_tensor)\n",
    "    assert torch.equal(reduced_tensor, expected_tensor), f\"Test failed: {reduced_tensor} != {expected_tensor}\"\n",
    "    \n",
    "    print(\"Test passed successfully!\")\n",
    "\n",
    "# Run the test\n",
    "test_reduce_tensor()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:vimAndMamba] *",
   "language": "python",
   "name": "conda-env-vimAndMamba-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
